{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3a4ff13-39e5-43e5-8e4a-5dc35a31a712",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Model Management\n",
    "\n",
    "A MLflow **`pyfunc`** allows for fully customizable deployments.\n",
    "\n",
    " - Model management best practices\n",
    " - Build a model with preprocessing logic, a loader module, side artifacts, a training method, and a custom environment\n",
    " - Apply the custom ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f9e95ec-130b-4b68-8178-9e19c323cbc1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Managing Machine Learning Models\n",
    "\n",
    "Once a model has been trained and bundled with the environment it was trained in the next step is to package the model so that it can be used by a variety of serving tools. **Packaging the final model in a platform-agnostic way offers the most flexibility in deployment options and allows for model reuse across a number of platforms.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3345c8c8-6b49-4f18-92e5-11595b4dc78d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "**MLflow models is a convention for packaging machine learning models that offers self-contained code, environments, and models.**<br><br>\n",
    "\n",
    "* The main abstraction in this package is the concept of **flavors**\n",
    "  - A flavor is a different ways the model can be used\n",
    "  - For instance, a TensorFlow model can be loaded as a TensorFlow DAG or as a Python function\n",
    "  - Using an MLflow model convention allows for both of these flavors\n",
    "* The `python_function` or `pyfunc` flavor of models gives a generic way of bundling models\n",
    "* We can thereby deploy a python function without worrying about the underlying format of the model\n",
    "\n",
    "**MLflow therefore maps any training framework to any deployment** using these platform-agnostic representations, massively reducing the complexity of inference.\n",
    "\n",
    "Arbitrary logic including pre and post-processing steps, arbitrary code executed when loading the model, side artifacts, and more can be included in the pipeline to customize it as needed.  This means that the full pipeline, not just the model, can be preserved as a single object that works with the rest of the MLflow ecosystem.\n",
    "\n",
    "<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-4/mlflow-models-enviornments.png\" style=\"height: 400px; margin: 20px\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af3c15e8-4324-4428-b928-b7cf2616fefa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Some of the most popular built-in flavors include the following:<br><br>\n",
    "\n",
    "* <a href=\"https://mlflow.org/docs/latest/python_api/mlflow.keras.html#module-mlflow.keras\" target=\"_blank\">mlflow.keras</a>\n",
    "* <a href=\"https://mlflow.org/docs/latest/python_api/mlflow.sklearn.html#module-mlflow.sklearn\" target=\"_blank\">mlflow.sklearn</a>\n",
    "* <a href=\"https://mlflow.org/docs/latest/python_api/mlflow.spark.html#module-mlflow.spark\" target=\"_blank\">mlflow.spark</a>\n",
    "\n",
    "<a href=\"https://mlflow.org/docs/latest/python_api/index.html\" target=\"_blank\">You can see all of the flavors and modules here.</a>\n",
    "\n",
    "<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-4/mlflow-models.png\" style=\"height: 400px; margin: 20px\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "510cc4e5-201e-4f43-b049-bfbd24a09ff6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "### Custom Models using `pyfunc`\n",
    "\n",
    "A **`pyfunc`** is a generic python model that can define any arbitrary logic, regardless of the libraries used to train it. **This object interoperates with any MLflow functionality, especially downstream scoring tools.**  As such, it's defined as a class with a related directory structure with all of the dependencies.  It is then \"just an object\" with a various methods such as a predict method.  Since it makes very few assumptions, it can be deployed using MLflow, SageMaker, a Spark UDF, or in any other environment.\n",
    "\n",
    "Check out <a href=\"https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#pyfunc-create-custom\" target=\"_blank\">the **`pyfunc`** documentation for details</a><br>\n",
    "Check out <a href=\"https://github.com/mlflow/mlflow/blob/master/docs/source/models.rst#example-saving-an-xgboost-model-in-mlflow-format\" target=\"_blank\">this README for generic example code and integration with **`XGBoost`**</a><br>\n",
    "Check out <a href=\"https://mlflow.org/docs/latest/models.html#example-creating-a-custom-add-n-model\" target=\"_blank\">this eaxmple that creates a basic class that adds **`n`** to the input values</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffe09fdb-78f2-4ec8-b698-a69f88974b16",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Possible reprocessing steps:\n",
    "\n",
    "1. Create an additional feature\n",
    "2. Enforce the proper data types\n",
    "\n",
    "When creating predictions from our model, we need to re-apply the same pre-processing logic to the data each time we use our model. \n",
    "\n",
    "To streamline the steps, we define a custom **`RFWithPreprocess`** model class that uses a **`preprocess_input(self, model_input)`** helper method to automatically pre-processes the raw input it receives before executing a custom **`fit()`** method or before passing that input into the trained model's **`.predict()`** function. This way, in future applications of our model we will no longer have to handle arbitrary pre-processing logic for every batch of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3412974b-4b5e-4f61-8683-2e8ab02e309d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a62b7d5-ff43-4c1c-9683-dcec1f17a205",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "white_wine = pd.read_csv(\"/dbfs/databricks-datasets/wine-quality/winequality-white.csv\", sep=\";\")\n",
    "red_wine = pd.read_csv(\"/dbfs/databricks-datasets/wine-quality/winequality-red.csv\", sep=\";\")\n",
    "\n",
    "red_wine['is_red'] = 1\n",
    "white_wine['is_red'] = 0\n",
    "\n",
    "data = pd.concat([red_wine, white_wine], axis=0)\n",
    "\n",
    "# Remove spaces from column names\n",
    "data.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)\n",
    "\n",
    "high_quality = (data.quality >= 7).astype(int)\n",
    "data.quality = high_quality\n",
    "\n",
    "data.reset_index(drop=True,inplace=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f358bd5-ce8d-496d-8884-16d6a87903cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6497 entries, 0 to 6496\nData columns (total 13 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   fixed_acidity         6497 non-null   float64\n 1   volatile_acidity      6497 non-null   float64\n 2   citric_acid           6497 non-null   float64\n 3   residual_sugar        6497 non-null   float64\n 4   chlorides             6497 non-null   float64\n 5   free_sulfur_dioxide   6497 non-null   float64\n 6   total_sulfur_dioxide  6497 non-null   float64\n 7   density               6497 non-null   float64\n 8   pH                    6497 non-null   float64\n 9   sulphates             6497 non-null   float64\n 10  alcohol               6497 non-null   float64\n 11  quality               6497 non-null   int64  \n 12  is_red                6497 non-null   int64  \ndtypes: float64(11), int64(2)\nmemory usage: 660.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72936d47-0f90-4a55-924a-c21966652062",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, random_state=123)\n",
    "X_train = train.drop([\"quality\"], axis=1)\n",
    "X_test = test.drop([\"quality\"], axis=1)\n",
    "y_train = train.quality\n",
    "y_test = test.quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c1eac78-a19a-43fe-b6db-5b3232277876",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Here is not necessary to preprocessing our data, but what happen when we have a repetitive code ? And what happens when we need to replicate this in a deployment system? Take a look at the following code instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24bbee1d-6f95-44d6-8e76-aa52a5cb0b9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import json\n",
    "\n",
    "class RFWithPreprocess(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        \"\"\"\n",
    "        Initialize with just the model hyperparameters\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        self.rf_model = None\n",
    "        self.config = None\n",
    "        \n",
    "    def load_context(self, context=None, config_path=None):\n",
    "        \"\"\"\n",
    "        When loading a pyfunc, this method runs automatically with the related\n",
    "        context.  This method is designed to perform the same functionality when\n",
    "        run in a notebook or a downstream operation (like a REST endpoint).\n",
    "        If the `context` object is provided, it will load the path to a config from \n",
    "        that object (this happens with `mlflow.pyfunc.load_model()` is called).\n",
    "        If the `config_path` argument is provided instead, it uses this argument\n",
    "        in order to load in the config.\n",
    "        \"\"\"\n",
    "        if context: # This block executes for server run\n",
    "            config_path = context.artifacts[\"config_path\"]\n",
    "        else: # This block executes for notebook run\n",
    "            pass\n",
    "\n",
    "        self.config = json.load(open(config_path))\n",
    "      \n",
    "    def preprocess_input(self, model_input):\n",
    "        \"\"\"\n",
    "        Return pre-processed model_input\n",
    "        \"\"\"\n",
    "        processed_input = model_input.copy()\n",
    "        \"\"\"\n",
    "            Here all the preprocessing\n",
    "        \"\"\"\n",
    "        print(\"Data Preprocesed\")\n",
    "        return processed_input\n",
    "  \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Uses the same preprocessing logic to fit the model\n",
    "        \"\"\"\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "        processed_model_input = self.preprocess_input(X_train)\n",
    "        rf_model = RandomForestClassifier(**self.params)\n",
    "        rf_model.fit(processed_model_input, y_train)\n",
    "\n",
    "        self.rf_model = rf_model\n",
    "    \n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"\n",
    "        This is the main entrance to the model in deployment systems\n",
    "        \"\"\"\n",
    "        processed_model_input = self.preprocess_input(model_input.copy())\n",
    "        return self.rf_model.predict(processed_model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad7462c0-c715-4abe-80d7-9b351ef190cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "The **`context`** parameter is provided automatically by MLflow in downstream tools. This can be used to add custom dependent objects such as models that are not easily serialized (e.g. **`keras`** models) or custom configuration files.\n",
    "\n",
    "Use the following to provide a config file. Note the steps:<br><br>\n",
    "\n",
    "- Save out any file we want to load into the class\n",
    "- Create an artifact dictionary of key/value pairs where the value is the path to that object\n",
    "- When saving the model, all artifacts will be copied over into the same directory for downstream use\n",
    "\n",
    "In our case, we'll save some model hyperparameters as our config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1410207e-3426-48e1-9aed-0f9101630263",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 15, \n",
    "    \"max_depth\": 5\n",
    "}\n",
    "\n",
    "# Designate a path\n",
    "config_path = f\"/data.json\"\n",
    "\n",
    "# Save the results\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump(params, f)\n",
    "\n",
    "# Generate an artifact object to saved\n",
    "# All paths to the associated values will be copied over when saving\n",
    "artifacts = {\"config_path\": config_path} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1a985b3-af5c-4c6e-af41-a6acc7965865",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Instantiate the class. Run **`load_context`** to load the config. This automatically runs in downstream serving tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36c5273e-4d6d-462f-ab87-be6b85b5bf57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[26]: {'n_estimators': 15, 'max_depth': 5}"
     ]
    }
   ],
   "source": [
    "model = RFWithPreprocess(params)\n",
    "\n",
    "# Run manually (this happens automatically in serving integrations)\n",
    "model.load_context(config_path=config_path) \n",
    "\n",
    "# Confirm the config has loaded\n",
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3ed0001-d71c-4fe1-8500-a257db653424",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Train the model. Note that this runs the preprocessing logic for us automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8929544-4176-4350-8e85-ce523032bf93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocesed\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e30a2877-98ef-4fce-bd3a-2e8e6548d982",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3b6c7a6-692f-42a0-8bbb-ff317588e411",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocesed\nOut[28]: array([0, 0, 0, ..., 0, 0, 0])"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(context=None, model_input=X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba7d9c79-dca1-4f27-b275-8b35bbbc96d5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Generate the model signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35dd2bc7-d5b7-4fa9-956d-144af09dc742",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>is_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.041</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.99258</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.59</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.037</td>\n",
       "      <td>21.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.99180</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.37</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.042</td>\n",
       "      <td>105.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.99189</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.59</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5780</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.32</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.039</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.99163</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.52</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>10.6</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.067</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.99870</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.86</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed_acidity</th>\n      <th>volatile_acidity</th>\n      <th>citric_acid</th>\n      <th>residual_sugar</th>\n      <th>chlorides</th>\n      <th>free_sulfur_dioxide</th>\n      <th>total_sulfur_dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>is_red</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1321</th>\n      <td>5.0</td>\n      <td>0.74</td>\n      <td>0.00</td>\n      <td>1.20</td>\n      <td>0.041</td>\n      <td>16.0</td>\n      <td>46.0</td>\n      <td>0.99258</td>\n      <td>4.01</td>\n      <td>0.59</td>\n      <td>12.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2767</th>\n      <td>7.2</td>\n      <td>0.20</td>\n      <td>0.38</td>\n      <td>1.00</td>\n      <td>0.037</td>\n      <td>21.0</td>\n      <td>74.0</td>\n      <td>0.99180</td>\n      <td>3.21</td>\n      <td>0.37</td>\n      <td>11.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5069</th>\n      <td>6.7</td>\n      <td>0.24</td>\n      <td>0.30</td>\n      <td>3.85</td>\n      <td>0.042</td>\n      <td>105.0</td>\n      <td>179.0</td>\n      <td>0.99189</td>\n      <td>3.04</td>\n      <td>0.59</td>\n      <td>11.3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5780</th>\n      <td>6.6</td>\n      <td>0.25</td>\n      <td>0.32</td>\n      <td>5.60</td>\n      <td>0.039</td>\n      <td>15.0</td>\n      <td>68.0</td>\n      <td>0.99163</td>\n      <td>2.96</td>\n      <td>0.52</td>\n      <td>11.1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>547</th>\n      <td>10.6</td>\n      <td>0.31</td>\n      <td>0.49</td>\n      <td>2.50</td>\n      <td>0.067</td>\n      <td>6.0</td>\n      <td>21.0</td>\n      <td>0.99870</td>\n      <td>3.26</td>\n      <td>0.86</td>\n      <td>10.7</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "761ccac2-5134-4eb9-83d7-434597e793b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.9/site-packages/mlflow/models/signature.py:130: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  inputs = _infer_schema(model_input)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[35]: inputs: \n  ['fixed_acidity': double, 'volatile_acidity': double, 'citric_acid': double, 'residual_sugar': double, 'chlorides': double, 'free_sulfur_dioxide': double, 'total_sulfur_dioxide': double, 'density': double, 'pH': double, 'sulphates': double, 'alcohol': double, 'is_red': long]\noutputs: \n  [Tensor('int64', (-1,))]"
     ]
    }
   ],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "signature = infer_signature(X_test, predictions)\n",
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca3bda27-f328-4f77-a119-252eed79ea33",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Generate the conda environment. This can be arbitrarily complex. This is necessary because when we use **`mlflow.sklearn`**, we automatically log the appropriate version of **`sklearn`**. With a **`pyfunc`**, we must manually construct our deployment environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "484d4e6a-26a1-45c8-af93-919cf5f04ba1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[31]: {'channels': ['defaults'],\n 'dependencies': ['python=3.9.5',\n  'pip',\n  {'pip': ['mlflow', 'scikit-learn==1.0.2']}],\n 'name': 'sklearn_env'}"
     ]
    }
   ],
   "source": [
    "from sys import version_info\n",
    "import sklearn\n",
    "\n",
    "conda_env = {\n",
    "    \"channels\": [\"defaults\"],\n",
    "    \"dependencies\": [\n",
    "        f\"python={version_info.major}.{version_info.minor}.{version_info.micro}\",\n",
    "        \"pip\",\n",
    "        {\"pip\": [\"mlflow\",\n",
    "                 f\"scikit-learn=={sklearn.__version__}\"]\n",
    "        },\n",
    "    ],\n",
    "    \"name\": \"sklearn_env\"\n",
    "}\n",
    "\n",
    "conda_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee79efb4-1f11-4169-b91e-a4dbcb313f18",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef519548-8ba6-478a-8bca-6ff6965ca9f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    mlflow.pyfunc.log_model(\n",
    "        \"rf_preprocessed_model\", \n",
    "        python_model=model, \n",
    "        artifacts=artifacts,\n",
    "        conda_env=conda_env,\n",
    "        signature=signature,\n",
    "        input_example=X_test[:3] \n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88a5aa1c-20b7-4b3a-92f1-39b532b8fdd0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Load the model in **`python_function`** format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6369c345-8dc3-4878-906c-fc31ba0f7389",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow_pyfunc_model_path = f\"runs:/{run.info.run_id}/rf_preprocessed_model\"\n",
    "loaded_preprocess_model = mlflow.pyfunc.load_model(mlflow_pyfunc_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13fbdad7-1677-4e50-88d3-cb3c99793ad5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Apply the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "096e3f5c-320c-4434-b2ce-f451f40849fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocesed\nOut[34]: array([0, 0, 0, ..., 0, 0, 0])"
     ]
    }
   ],
   "source": [
    "loaded_preprocess_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e6c03e9-66f7-428e-a81c-cd071b0d19ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Note that `pyfunc`'s interoperate with any downstream serving tool. It allows you to use arbitrary code, niche libraries, and complex side information.**"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Sesion 3 - Model - Management",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
