{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps con Databricks: Gu√≠a Completa\n",
    "\n",
    "## üìö Objetivos de Aprendizaje\n",
    "\n",
    "En este notebook aprender√°s:\n",
    "1. **Desarrollo de modelos** con seguimiento autom√°tico\n",
    "2. **MLflow** para experimentaci√≥n y tracking\n",
    "3. **Feature Store** para gesti√≥n de features\n",
    "4. **Model Registry** para versionado y gobernanza\n",
    "5. **Model Serving** para deployment en producci√≥n\n",
    "6. **Monitoreo** de modelos en producci√≥n\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Caso de Uso: Predicci√≥n de Churn en Telecomunicaciones\n",
    "\n",
    "**Contexto de Negocio:**\n",
    "Una empresa de telecomunicaciones necesita predecir qu√© clientes est√°n en riesgo de cancelar su servicio (churn). El equipo de marketing puede entonces ofrecer incentivos personalizados para retenerlos.\n",
    "\n",
    "**Requisitos MLOps:**\n",
    "- Reentrenamiento mensual del modelo\n",
    "- Monitoreo de performance en producci√≥n\n",
    "- Versionado de modelos y features\n",
    "- Deployment automatizado\n",
    "- Trazabilidad completa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Setup Inicial y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de librer√≠as necesarias\n",
    "# En Databricks, muchas de estas librer√≠as ya est√°n preinstaladas\n",
    "%pip install mlflow==2.10.0 databricks-feature-engineering scikit-learn==1.3.2\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Databricks Feature Store\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    f1_score, roc_auc_score, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Spark\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de MLflow\n",
    "username = spark.sql(\"SELECT current_user()\").first()[0]\n",
    "experiment_name = f\"/Users/{username}/mlops_telco_churn\"\n",
    "\n",
    "# Crear o obtener el experimento\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Configuraci√≥n del Feature Store\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "# Nombres de cat√°logo y schema (usar Unity Catalog)\n",
    "catalog_name = \"main\"  # Ajustar seg√∫n tu configuraci√≥n\n",
    "schema_name = \"mlops_demo\"\n",
    "database_name = f\"{catalog_name}.{schema_name}\"\n",
    "\n",
    "# Crear schema si no existe\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {database_name}\")\n",
    "\n",
    "print(f\"üìä Experimento: {experiment_name}\")\n",
    "print(f\"üìÅ Database: {database_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Generaci√≥n de Datos Sint√©ticos\n",
    "\n",
    "**üìù Nota Pedag√≥gica:**\n",
    "En producci√≥n, estos datos vendr√≠an de tus fuentes reales (Data Lake, bases de datos, APIs). Aqu√≠ generamos datos sint√©ticos para simular un escenario realista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar dataset sint√©tico de clientes\n",
    "np.random.seed(42)\n",
    "n_customers = 5000\n",
    "\n",
    "# IDs y datos demogr√°ficos\n",
    "customer_ids = [f\"CUST_{i:05d}\" for i in range(n_customers)]\n",
    "ages = np.random.randint(18, 75, n_customers)\n",
    "tenure_months = np.random.randint(1, 72, n_customers)\n",
    "monthly_charges = np.random.uniform(20, 120, n_customers)\n",
    "\n",
    "# Servicios contratados\n",
    "internet_service = np.random.choice(['DSL', 'Fiber', 'No'], n_customers)\n",
    "has_phone = np.random.choice([0, 1], n_customers, p=[0.3, 0.7])\n",
    "has_streaming = np.random.choice([0, 1], n_customers, p=[0.6, 0.4])\n",
    "contract_type = np.random.choice(['Month-to-month', 'One year', 'Two year'], \n",
    "                                  n_customers, p=[0.5, 0.3, 0.2])\n",
    "\n",
    "# Comportamiento de uso\n",
    "monthly_minutes = np.random.randint(100, 2000, n_customers)\n",
    "data_usage_gb = np.random.uniform(1, 50, n_customers)\n",
    "support_tickets = np.random.poisson(lam=1.5, size=n_customers)\n",
    "payment_method = np.random.choice(['Credit card', 'Bank transfer', 'Electronic check'],\n",
    "                                   n_customers, p=[0.4, 0.3, 0.3])\n",
    "\n",
    "# Generar churn con l√≥gica de negocio\n",
    "churn_probability = (\n",
    "    0.05 +  # Base rate\n",
    "    0.3 * (contract_type == 'Month-to-month') +\n",
    "    0.2 * (tenure_months < 12) +\n",
    "    0.15 * (support_tickets > 3) +\n",
    "    0.1 * (payment_method == 'Electronic check') -\n",
    "    0.1 * (has_streaming == 1)\n",
    ")\n",
    "churn = (np.random.random(n_customers) < churn_probability).astype(int)\n",
    "\n",
    "# Crear DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'customer_id': customer_ids,\n",
    "    'age': ages,\n",
    "    'tenure_months': tenure_months,\n",
    "    'monthly_charges': monthly_charges,\n",
    "    'internet_service': internet_service,\n",
    "    'has_phone_service': has_phone,\n",
    "    'has_streaming': has_streaming,\n",
    "    'contract_type': contract_type,\n",
    "    'monthly_minutes': monthly_minutes,\n",
    "    'data_usage_gb': data_usage_gb,\n",
    "    'support_tickets': support_tickets,\n",
    "    'payment_method': payment_method,\n",
    "    'churn': churn\n",
    "})\n",
    "\n",
    "print(f\"‚úÖ Dataset generado: {len(data):,} clientes\")\n",
    "print(f\"üìä Tasa de churn: {churn.mean():.2%}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis exploratorio r√°pido\n",
    "print(\"\\nüìà DISTRIBUCI√ìN DE CHURN\\n\" + \"=\"*50)\n",
    "print(data.groupby('churn').size())\n",
    "\n",
    "print(\"\\nüìä ESTAD√çSTICAS POR CONTRATO\\n\" + \"=\"*50)\n",
    "print(data.groupby('contract_type')['churn'].agg(['count', 'mean']))\n",
    "\n",
    "print(\"\\nüîç CORRELACI√ìN CON CHURN\\n\" + \"=\"*50)\n",
    "numeric_cols = ['age', 'tenure_months', 'monthly_charges', 'support_tickets']\n",
    "correlations = data[numeric_cols + ['churn']].corr()['churn'].sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Feature Store: Gesti√≥n Centralizada de Features\n",
    "\n",
    "**üéØ ¬øPor qu√© Feature Store?**\n",
    "- **Reutilizaci√≥n**: Features compartidas entre equipos\n",
    "- **Consistencia**: Mismas features en training y serving\n",
    "- **Gobernanza**: Versionado y linaje de features\n",
    "- **Performance**: Features pre-computadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a Spark DataFrame\n",
    "spark_df = spark.createDataFrame(data)\n",
    "\n",
    "# Agregar timestamp (en producci√≥n vendr√≠a de tus datos)\n",
    "spark_df = spark_df.withColumn(\n",
    "    \"update_timestamp\",\n",
    "    F.current_timestamp()\n",
    ")\n",
    "\n",
    "display(spark_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING: Crear features derivadas\n",
    "features_df = spark_df.select(\n",
    "    \"customer_id\",\n",
    "    \"update_timestamp\",\n",
    "    \n",
    "    # Features base\n",
    "    \"age\",\n",
    "    \"tenure_months\",\n",
    "    \"monthly_charges\",\n",
    "    \"monthly_minutes\",\n",
    "    \"data_usage_gb\",\n",
    "    \"support_tickets\",\n",
    "    \n",
    "    # Features derivadas - Engagement\n",
    "    (F.col(\"monthly_charges\") / F.col(\"tenure_months\")).alias(\"avg_monthly_spend\"),\n",
    "    (F.col(\"data_usage_gb\") / 30).alias(\"daily_data_usage\"),\n",
    "    (F.col(\"support_tickets\") / F.col(\"tenure_months\")).alias(\"tickets_per_month\"),\n",
    "    \n",
    "    # Features categ√≥ricas one-hot encoded\n",
    "    F.when(F.col(\"internet_service\") == \"DSL\", 1).otherwise(0).alias(\"is_dsl\"),\n",
    "    F.when(F.col(\"internet_service\") == \"Fiber\", 1).otherwise(0).alias(\"is_fiber\"),\n",
    "    F.when(F.col(\"contract_type\") == \"Month-to-month\", 1).otherwise(0).alias(\"is_monthly_contract\"),\n",
    "    F.when(F.col(\"contract_type\") == \"One year\", 1).otherwise(0).alias(\"is_yearly_contract\"),\n",
    "    F.when(F.col(\"payment_method\") == \"Electronic check\", 1).otherwise(0).alias(\"is_electronic_check\"),\n",
    "    \n",
    "    # Servicios adicionales\n",
    "    F.col(\"has_phone_service\"),\n",
    "    F.col(\"has_streaming\"),\n",
    "    \n",
    "    # Segmentaci√≥n de clientes\n",
    "    F.when(F.col(\"tenure_months\") < 6, \"new\")\n",
    "     .when(F.col(\"tenure_months\") < 24, \"regular\")\n",
    "     .otherwise(\"loyal\").alias(\"customer_segment\"),\n",
    "    \n",
    "    # Target (solo para training)\n",
    "    \"churn\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Features engineered creadas\")\n",
    "display(features_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear Feature Table en Feature Store\n",
    "feature_table_name = f\"{database_name}.customer_churn_features\"\n",
    "\n",
    "try:\n",
    "    # Crear la feature table\n",
    "    fe.create_table(\n",
    "        name=feature_table_name,\n",
    "        primary_keys=[\"customer_id\"],\n",
    "        timestamp_keys=[\"update_timestamp\"],\n",
    "        df=features_df,\n",
    "        description=\"Features de clientes para predicci√≥n de churn en telecomunicaciones\"\n",
    "    )\n",
    "    print(f\"‚úÖ Feature table creada: {feature_table_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(f\"‚ö†Ô∏è  Feature table ya existe, actualizando datos...\")\n",
    "        # Actualizar con merge\n",
    "        fe.write_table(\n",
    "            name=feature_table_name,\n",
    "            df=features_df,\n",
    "            mode=\"merge\"\n",
    "        )\n",
    "        print(f\"‚úÖ Feature table actualizada: {feature_table_name}\")\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "# Verificar la tabla\n",
    "feature_table = spark.table(feature_table_name)\n",
    "print(f\"\\nüìä Total de registros: {feature_table.count():,}\")\n",
    "print(f\"üìä Total de features: {len(feature_table.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Experimentaci√≥n con MLflow\n",
    "\n",
    "**üî¨ MLflow Tracking:**\n",
    "- Registra autom√°ticamente par√°metros, m√©tricas y artefactos\n",
    "- Compara m√∫ltiples experimentos\n",
    "- Reproduce resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para entrenamiento\n",
    "training_data = feature_table.toPandas()\n",
    "\n",
    "# Separar features y target\n",
    "feature_columns = [\n",
    "    'age', 'tenure_months', 'monthly_charges', 'monthly_minutes', \n",
    "    'data_usage_gb', 'support_tickets', 'avg_monthly_spend',\n",
    "    'daily_data_usage', 'tickets_per_month', 'is_dsl', 'is_fiber',\n",
    "    'is_monthly_contract', 'is_yearly_contract', 'is_electronic_check',\n",
    "    'has_phone_service', 'has_streaming'\n",
    "]\n",
    "\n",
    "X = training_data[feature_columns]\n",
    "y = training_data['churn']\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Datos preparados para entrenamiento\")\n",
    "print(f\"   Training set: {len(X_train):,} samples\")\n",
    "print(f\"   Test set: {len(X_test):,} samples\")\n",
    "print(f\"   Features: {len(feature_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n helper para entrenar y evaluar modelos\n",
    "def train_and_evaluate_model(model, model_name, X_train, X_test, y_train, y_test, params=None):\n",
    "    \"\"\"\n",
    "    Entrena un modelo y registra m√©tricas en MLflow\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=model_name) as run:\n",
    "        \n",
    "        # Activar autolog para el framework correspondiente\n",
    "        mlflow.sklearn.autolog(log_models=False)  # Registraremos el modelo manualmente\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        print(f\"\\nüöÄ Entrenando {model_name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predicciones\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # M√©tricas\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        \n",
    "        # Log m√©tricas adicionales\n",
    "        mlflow.log_metrics({\n",
    "            \"test_accuracy\": accuracy,\n",
    "            \"test_precision\": precision,\n",
    "            \"test_recall\": recall,\n",
    "            \"test_f1_score\": f1,\n",
    "            \"test_roc_auc\": roc_auc\n",
    "        })\n",
    "        \n",
    "        # Log par√°metros del modelo\n",
    "        if params:\n",
    "            mlflow.log_params(params)\n",
    "        \n",
    "        # Log confusion matrix como artefacto\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        cm_df = pd.DataFrame(\n",
    "            cm, \n",
    "            index=['Actual No Churn', 'Actual Churn'],\n",
    "            columns=['Predicted No Churn', 'Predicted Churn']\n",
    "        )\n",
    "        cm_df.to_csv('/tmp/confusion_matrix.csv')\n",
    "        mlflow.log_artifact('/tmp/confusion_matrix.csv')\n",
    "        \n",
    "        # Feature importance (si est√° disponible)\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': feature_columns,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            feature_importance.to_csv('/tmp/feature_importance.csv', index=False)\n",
    "            mlflow.log_artifact('/tmp/feature_importance.csv')\n",
    "        \n",
    "        # Registrar modelo con signature\n",
    "        signature = infer_signature(X_train, y_pred_proba)\n",
    "        \n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=\"model\",\n",
    "            signature=signature,\n",
    "            registered_model_name=f\"telco_churn_{model_name.lower().replace(' ', '_')}\"\n",
    "        )\n",
    "        \n",
    "        # Imprimir resultados\n",
    "        print(f\"\\nüìä Resultados de {model_name}:\")\n",
    "        print(f\"   Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"   Precision: {precision:.4f}\")\n",
    "        print(f\"   Recall:    {recall:.4f}\")\n",
    "        print(f\"   F1-Score:  {f1:.4f}\")\n",
    "        print(f\"   ROC-AUC:   {roc_auc:.4f}\")\n",
    "        print(f\"\\n   Confusion Matrix:\")\n",
    "        print(cm_df)\n",
    "        \n",
    "        return run.info.run_id, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENTO 1: Logistic Regression (baseline)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_params = {\n",
    "    'max_iter': 1000,\n",
    "    'solver': 'lbfgs'\n",
    "}\n",
    "\n",
    "lr_run_id, lr_trained = train_and_evaluate_model(\n",
    "    lr_model, \n",
    "    \"Logistic Regression\", \n",
    "    X_train, X_test, y_train, y_test,\n",
    "    params=lr_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENTO 2: Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5\n",
    "}\n",
    "\n",
    "rf_run_id, rf_trained = train_and_evaluate_model(\n",
    "    rf_model,\n",
    "    \"Random Forest\",\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    params=rf_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENTO 3: Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5\n",
    "}\n",
    "\n",
    "gb_run_id, gb_trained = train_and_evaluate_model(\n",
    "    gb_model,\n",
    "    \"Gradient Boosting\",\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    params=gb_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar todos los modelos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä COMPARACI√ìN DE MODELOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Obtener runs del experimento\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "runs_df = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"metrics.test_roc_auc DESC\"]\n",
    ")\n",
    "\n",
    "# Mostrar comparaci√≥n\n",
    "comparison_cols = [\n",
    "    'run_id', \n",
    "    'tags.mlflow.runName',\n",
    "    'metrics.test_accuracy',\n",
    "    'metrics.test_precision',\n",
    "    'metrics.test_recall',\n",
    "    'metrics.test_f1_score',\n",
    "    'metrics.test_roc_auc'\n",
    "]\n",
    "\n",
    "display(runs_df[comparison_cols].head())\n",
    "\n",
    "best_model_name = runs_df.iloc[0]['tags.mlflow.runName']\n",
    "best_auc = runs_df.iloc[0]['metrics.test_roc_auc']\n",
    "print(f\"\\nüèÜ Mejor modelo: {best_model_name} (ROC-AUC: {best_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Model Registry: Gesti√≥n del Ciclo de Vida\n",
    "\n",
    "**üóÇÔ∏è Stages del Model Registry:**\n",
    "- **None**: Modelo registrado pero no promovido\n",
    "- **Staging**: Modelo en testing/QA\n",
    "- **Production**: Modelo en producci√≥n activo\n",
    "- **Archived**: Modelo deprecado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor modelo del experimento\n",
    "best_run = runs_df.iloc[0]\n",
    "best_run_id = best_run['run_id']\n",
    "best_model_name = best_run['tags.mlflow.runName']\n",
    "\n",
    "print(f\"üèÜ Promoviendo modelo a Staging: {best_model_name}\")\n",
    "print(f\"   Run ID: {best_run_id}\")\n",
    "\n",
    "# Obtener el modelo URI\n",
    "model_uri = f\"runs:/{best_run_id}/model\"\n",
    "registered_model_name = \"telco_churn_production\"\n",
    "\n",
    "# Registrar el modelo (si no existe)\n",
    "try:\n",
    "    model_details = mlflow.register_model(\n",
    "        model_uri=model_uri,\n",
    "        name=registered_model_name\n",
    "    )\n",
    "    model_version = model_details.version\n",
    "    print(f\"‚úÖ Modelo registrado como versi√≥n {model_version}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error registrando modelo: {e}\")\n",
    "    # Si el modelo ya existe, obtener la √∫ltima versi√≥n\n",
    "    client = mlflow.MlflowClient()\n",
    "    latest_versions = client.get_latest_versions(registered_model_name)\n",
    "    model_version = latest_versions[0].version if latest_versions else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transicionar modelo a Staging\n",
    "client = mlflow.MlflowClient()\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=registered_model_name,\n",
    "    version=model_version,\n",
    "    stage=\"Staging\",\n",
    "    archive_existing_versions=True  # Archivar versiones anteriores en Staging\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Modelo transicionado a Staging\")\n",
    "\n",
    "# Agregar descripci√≥n y tags\n",
    "client.update_model_version(\n",
    "    name=registered_model_name,\n",
    "    version=model_version,\n",
    "    description=f\"Modelo {best_model_name} entrenado el {datetime.now().strftime('%Y-%m-%d')}. ROC-AUC: {best_auc:.4f}\"\n",
    ")\n",
    "\n",
    "client.set_model_version_tag(\n",
    "    name=registered_model_name,\n",
    "    version=model_version,\n",
    "    key=\"model_type\",\n",
    "    value=best_model_name\n",
    ")\n",
    "\n",
    "client.set_model_version_tag(\n",
    "    name=registered_model_name,\n",
    "    version=model_version,\n",
    "    key=\"training_date\",\n",
    "    value=datetime.now().strftime('%Y-%m-%d')\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Metadata agregada al modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular validaci√≥n en Staging (normalmente har√≠as pruebas A/B, shadow mode, etc.)\n",
    "print(\"\\nüß™ VALIDACI√ìN EN STAGING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar modelo desde Staging\n",
    "model_staging_uri = f\"models:/{registered_model_name}/Staging\"\n",
    "loaded_model = mlflow.sklearn.load_model(model_staging_uri)\n",
    "\n",
    "# Validar en un conjunto de validaci√≥n\n",
    "y_val_pred_proba = loaded_model.predict_proba(X_test)[:, 1]\n",
    "y_val_pred = loaded_model.predict(X_test)\n",
    "\n",
    "val_accuracy = accuracy_score(y_test, y_val_pred)\n",
    "val_roc_auc = roc_auc_score(y_test, y_val_pred_proba)\n",
    "\n",
    "print(f\"‚úÖ Validaci√≥n completada\")\n",
    "print(f\"   Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"   ROC-AUC: {val_roc_auc:.4f}\")\n",
    "\n",
    "# Criterio de promoci√≥n a producci√≥n\n",
    "MIN_ROC_AUC_THRESHOLD = 0.70\n",
    "\n",
    "if val_roc_auc >= MIN_ROC_AUC_THRESHOLD:\n",
    "    print(f\"\\n‚úÖ Modelo cumple criterios (ROC-AUC >= {MIN_ROC_AUC_THRESHOLD})\")\n",
    "    print(\"   Promoviendo a PRODUCTION...\")\n",
    "    \n",
    "    client.transition_model_version_stage(\n",
    "        name=registered_model_name,\n",
    "        version=model_version,\n",
    "        stage=\"Production\",\n",
    "        archive_existing_versions=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüöÄ Modelo en PRODUCTION (versi√≥n {model_version})\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Modelo NO cumple criterios (ROC-AUC < {MIN_ROC_AUC_THRESHOLD})\")\n",
    "    print(\"   Se requiere m√°s entrenamiento o ajuste de hiperpar√°metros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Inferencia y Predicciones\n",
    "\n",
    "**üîÆ Modos de Inferencia:**\n",
    "- **Batch**: Predicciones programadas sobre conjuntos grandes\n",
    "- **Real-time**: API endpoint para predicciones individuales\n",
    "- **Streaming**: Predicciones sobre datos en tiempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCIA BATCH: Predecir sobre nuevos clientes\n",
    "\n",
    "# Simular nuevos clientes (en producci√≥n vendr√≠an de tu pipeline de datos)\n",
    "new_customers = pd.DataFrame({\n",
    "    'customer_id': ['NEW_001', 'NEW_002', 'NEW_003'],\n",
    "    'age': [25, 45, 60],\n",
    "    'tenure_months': [3, 24, 48],\n",
    "    'monthly_charges': [85.0, 65.0, 45.0],\n",
    "    'monthly_minutes': [500, 1200, 800],\n",
    "    'data_usage_gb': [15.0, 8.0, 3.0],\n",
    "    'support_tickets': [5, 1, 0],\n",
    "    'avg_monthly_spend': [28.33, 2.71, 0.94],\n",
    "    'daily_data_usage': [0.5, 0.27, 0.1],\n",
    "    'tickets_per_month': [1.67, 0.04, 0.0],\n",
    "    'is_dsl': [0, 1, 0],\n",
    "    'is_fiber': [1, 0, 0],\n",
    "    'is_monthly_contract': [1, 0, 0],\n",
    "    'is_yearly_contract': [0, 1, 1],\n",
    "    'is_electronic_check': [1, 0, 0],\n",
    "    'has_phone_service': [1, 1, 1],\n",
    "    'has_streaming': [1, 1, 0]\n",
    "})\n",
    "\n",
    "print(\"üÜï Nuevos clientes para predecir:\")\n",
    "display(new_customers[['customer_id', 'age', 'tenure_months', 'monthly_charges']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo de producci√≥n\n",
    "model_prod_uri = f\"models:/{registered_model_name}/Production\"\n",
    "production_model = mlflow.sklearn.load_model(model_prod_uri)\n",
    "\n",
    "# Hacer predicciones\n",
    "new_customers_features = new_customers[feature_columns]\n",
    "churn_predictions = production_model.predict(new_customers_features)\n",
    "churn_probabilities = production_model.predict_proba(new_customers_features)[:, 1]\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "predictions_df = pd.DataFrame({\n",
    "    'customer_id': new_customers['customer_id'],\n",
    "    'churn_prediction': churn_predictions,\n",
    "    'churn_probability': churn_probabilities,\n",
    "    'risk_level': pd.cut(\n",
    "        churn_probabilities,\n",
    "        bins=[0, 0.3, 0.7, 1.0],\n",
    "        labels=['Bajo', 'Medio', 'Alto']\n",
    "    )\n",
    "})\n",
    "\n",
    "print(\"\\nüîÆ PREDICCIONES DE CHURN\")\n",
    "print(\"=\"*60)\n",
    "display(predictions_df)\n",
    "\n",
    "# Guardar predicciones (en producci√≥n ir√≠an a una tabla Delta)\n",
    "predictions_table_name = f\"{database_name}.churn_predictions\"\n",
    "spark_predictions = spark.createDataFrame(predictions_df)\n",
    "spark_predictions = spark_predictions.withColumn(\"prediction_timestamp\", F.current_timestamp())\n",
    "\n",
    "spark_predictions.write.mode(\"append\").saveAsTable(predictions_table_name)\n",
    "print(f\"\\n‚úÖ Predicciones guardadas en: {predictions_table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Monitoreo de Modelos en Producci√≥n\n",
    "\n",
    "**üìä ¬øQu√© monitorear?**\n",
    "- **Performance**: M√©tricas de negocio y ML\n",
    "- **Data Drift**: Cambios en la distribuci√≥n de features\n",
    "- **Prediction Drift**: Cambios en las predicciones\n",
    "- **Latencia**: Tiempo de respuesta\n",
    "- **Volumen**: N√∫mero de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular monitoreo de performance en producci√≥n\n",
    "# En la realidad, comparar√≠as predicciones con outcomes reales (cuando est√©n disponibles)\n",
    "\n",
    "def calculate_monitoring_metrics(predictions_df, actuals_df=None):\n",
    "    \"\"\"\n",
    "    Calcula m√©tricas de monitoreo para el modelo en producci√≥n\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Distribuci√≥n de predicciones\n",
    "    metrics['avg_churn_probability'] = predictions_df['churn_probability'].mean()\n",
    "    metrics['predicted_churn_rate'] = predictions_df['churn_prediction'].mean()\n",
    "    \n",
    "    # Distribuci√≥n de riesgo\n",
    "    risk_distribution = predictions_df['risk_level'].value_counts(normalize=True)\n",
    "    metrics['high_risk_percentage'] = risk_distribution.get('Alto', 0)\n",
    "    metrics['medium_risk_percentage'] = risk_distribution.get('Medio', 0)\n",
    "    metrics['low_risk_percentage'] = risk_distribution.get('Bajo', 0)\n",
    "    \n",
    "    # Si tenemos actuals, calcular performance real\n",
    "    if actuals_df is not None:\n",
    "        merged = predictions_df.merge(actuals_df, on='customer_id')\n",
    "        metrics['actual_accuracy'] = accuracy_score(\n",
    "            merged['actual_churn'], \n",
    "            merged['churn_prediction']\n",
    "        )\n",
    "        metrics['actual_roc_auc'] = roc_auc_score(\n",
    "            merged['actual_churn'],\n",
    "            merged['churn_probability']\n",
    "        )\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calcular m√©tricas\n",
    "monitoring_metrics = calculate_monitoring_metrics(predictions_df)\n",
    "\n",
    "print(\"\\nüìà M√âTRICAS DE MONITOREO\")\n",
    "print(\"=\"*60)\n",
    "for metric_name, metric_value in monitoring_metrics.items():\n",
    "    print(f\"{metric_name:.<40} {metric_value:.4f}\")\n",
    "\n",
    "# Log m√©tricas de monitoreo a MLflow\n",
    "with mlflow.start_run(run_name=\"production_monitoring\") as run:\n",
    "    mlflow.log_metrics(monitoring_metrics)\n",
    "    mlflow.log_param(\"monitoring_date\", datetime.now().strftime('%Y-%m-%d'))\n",
    "    mlflow.log_param(\"model_version\", model_version)\n",
    "    \n",
    "print(\"\\n‚úÖ M√©tricas de monitoreo registradas en MLflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA DRIFT MONITORING\n",
    "# Comparar distribuci√≥n de features entre entrenamiento y producci√≥n\n",
    "\n",
    "def check_data_drift(training_data, production_data, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Detecta drift comparando estad√≠sticas entre training y producci√≥n\n",
    "    \"\"\"\n",
    "    drift_report = []\n",
    "    \n",
    "    for feature in feature_columns:\n",
    "        # Calcular estad√≠sticas\n",
    "        train_mean = training_data[feature].mean()\n",
    "        train_std = training_data[feature].std()\n",
    "        \n",
    "        prod_mean = production_data[feature].mean()\n",
    "        prod_std = production_data[feature].std()\n",
    "        \n",
    "        # Calcular diferencia relativa\n",
    "        mean_diff = abs(prod_mean - train_mean) / (train_mean + 1e-10)\n",
    "        std_diff = abs(prod_std - train_std) / (train_std + 1e-10)\n",
    "        \n",
    "        # Detectar drift\n",
    "        has_drift = (mean_diff > threshold) or (std_diff > threshold)\n",
    "        \n",
    "        drift_report.append({\n",
    "            'feature': feature,\n",
    "            'train_mean': train_mean,\n",
    "            'prod_mean': prod_mean,\n",
    "            'mean_diff_%': mean_diff * 100,\n",
    "            'has_drift': has_drift\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(drift_report)\n",
    "\n",
    "# Detectar drift\n",
    "drift_df = check_data_drift(X_train, new_customers_features, threshold=0.15)\n",
    "\n",
    "print(\"\\nüö® DATA DRIFT ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Features con drift detectado: {drift_df['has_drift'].sum()}\")\n",
    "print(\"\\nTop 5 features con mayor diferencia:\")\n",
    "display(drift_df.nlargest(5, 'mean_diff_%')[['feature', 'mean_diff_%', 'has_drift']])\n",
    "\n",
    "# Si hay drift significativo, alertar\n",
    "if drift_df['has_drift'].sum() > len(feature_columns) * 0.3:\n",
    "    print(\"\\n‚ö†Ô∏è  ALERTA: Drift significativo detectado (>30% de features)\")\n",
    "    print(\"   Considerar reentrenamiento del modelo\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Drift dentro de l√≠mites aceptables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ CI/CD y Automatizaci√≥n\n",
    "\n",
    "**üîÑ Pipeline Automatizado:**\n",
    "```\n",
    "1. Trigger (schedule o evento)\n",
    "   ‚Üì\n",
    "2. Data Pipeline (actualizar Feature Store)\n",
    "   ‚Üì\n",
    "3. Training Pipeline (entrenar modelos)\n",
    "   ‚Üì\n",
    "4. Evaluation (validar performance)\n",
    "   ‚Üì\n",
    "5. Staging (deploy a staging)\n",
    "   ‚Üì\n",
    "6. Testing (A/B testing, shadow mode)\n",
    "   ‚Üì\n",
    "7. Production (deploy a producci√≥n)\n",
    "   ‚Üì\n",
    "8. Monitoring (alertas y dashboards)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJEMPLO: Funci√≥n de reentrenamiento automatizado\n",
    "\n",
    "def automated_retraining_pipeline(\n",
    "    feature_table_name,\n",
    "    model_name,\n",
    "    min_roc_auc_threshold=0.70,\n",
    "    retrain_if_drift=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Pipeline automatizado de reentrenamiento\n",
    "    \n",
    "    Esta funci√≥n se ejecutar√≠a en un Databricks Job programado\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîÑ INICIANDO PIPELINE DE REENTRENAMIENTO\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Cargar datos actualizados del Feature Store\n",
    "    print(\"\\n1Ô∏è‚É£ Cargando datos del Feature Store...\")\n",
    "    feature_data = spark.table(feature_table_name).toPandas()\n",
    "    print(f\"   ‚úÖ {len(feature_data):,} registros cargados\")\n",
    "    \n",
    "    # 2. Preparar datos\n",
    "    print(\"\\n2Ô∏è‚É£ Preparando datos...\")\n",
    "    X = feature_data[feature_columns]\n",
    "    y = feature_data['churn']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    print(f\"   ‚úÖ Train: {len(X_train):,} | Test: {len(X_test):,}\")\n",
    "    \n",
    "    # 3. Entrenar modelo\n",
    "    print(\"\\n3Ô∏è‚É£ Entrenando modelo...\")\n",
    "    with mlflow.start_run(run_name=\"automated_retraining\") as run:\n",
    "        # Usar el mejor algoritmo del experimento anterior\n",
    "        model = GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=5,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        mlflow.sklearn.autolog()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluar\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        \n",
    "        mlflow.log_metric(\"test_roc_auc\", roc_auc)\n",
    "        mlflow.log_param(\"retraining_date\", datetime.now().strftime('%Y-%m-%d'))\n",
    "        \n",
    "        print(f\"   ‚úÖ ROC-AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "        # 4. Validar performance\n",
    "        print(\"\\n4Ô∏è‚É£ Validando performance...\")\n",
    "        if roc_auc >= min_roc_auc_threshold:\n",
    "            print(f\"   ‚úÖ Modelo cumple threshold (>={min_roc_auc_threshold})\")\n",
    "            \n",
    "            # 5. Registrar y promover modelo\n",
    "            print(\"\\n5Ô∏è‚É£ Registrando modelo...\")\n",
    "            model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "            model_details = mlflow.register_model(\n",
    "                model_uri=model_uri,\n",
    "                name=model_name\n",
    "            )\n",
    "            \n",
    "            print(f\"   ‚úÖ Modelo registrado como versi√≥n {model_details.version}\")\n",
    "            \n",
    "            # Transicionar a Staging\n",
    "            client = mlflow.MlflowClient()\n",
    "            client.transition_model_version_stage(\n",
    "                name=model_name,\n",
    "                version=model_details.version,\n",
    "                stage=\"Staging\"\n",
    "            )\n",
    "            \n",
    "            print(\"   ‚úÖ Modelo promovido a Staging\")\n",
    "            print(\"\\n   ‚ö†Ô∏è  Requiere validaci√≥n manual antes de Production\")\n",
    "            \n",
    "            return True, model_details.version, roc_auc\n",
    "        else:\n",
    "            print(f\"   ‚ùå Modelo NO cumple threshold (<{min_roc_auc_threshold})\")\n",
    "            print(\"   ‚ö†Ô∏è  Reentrenamiento fallido - revisar datos y features\")\n",
    "            return False, None, roc_auc\n",
    "\n",
    "# Ejecutar pipeline (en producci√≥n esto ser√≠a un Databricks Job)\n",
    "success, new_version, new_roc_auc = automated_retraining_pipeline(\n",
    "    feature_table_name=feature_table_name,\n",
    "    model_name=registered_model_name,\n",
    "    min_roc_auc_threshold=0.70\n",
    ")\n",
    "\n",
    "if success:\n",
    "    print(f\"\\nüéâ REENTRENAMIENTO EXITOSO\")\n",
    "    print(f\"   Nueva versi√≥n: {new_version}\")\n",
    "    print(f\"   ROC-AUC: {new_roc_auc:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  REENTRENAMIENTO REQUIERE ATENCI√ìN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ Best Practices y Recomendaciones\n",
    "\n",
    "### üéØ Organizaci√≥n del Proyecto\n",
    "\n",
    "```\n",
    "mlops-project/\n",
    "‚îú‚îÄ‚îÄ notebooks/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 03_model_training.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ 04_model_evaluation.py\n",
    "‚îú‚îÄ‚îÄ src/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ features/\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_engineering.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ models/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ utils/\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ helpers.py\n",
    "‚îú‚îÄ‚îÄ tests/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ test_features.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ test_models.py\n",
    "‚îú‚îÄ‚îÄ configs/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ training_config.yaml\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ deployment_config.yaml\n",
    "‚îî‚îÄ‚îÄ workflows/\n",
    "    ‚îú‚îÄ‚îÄ training_pipeline.py\n",
    "    ‚îî‚îÄ‚îÄ deployment_pipeline.py\n",
    "```\n",
    "\n",
    "### üìã Checklist de MLOps\n",
    "\n",
    "#### Desarrollo\n",
    "- ‚úÖ Experimentos rastreados en MLflow\n",
    "- ‚úÖ Features versionadas en Feature Store\n",
    "- ‚úÖ C√≥digo versionado en Git\n",
    "- ‚úÖ Tests unitarios para features y modelos\n",
    "\n",
    "#### Deployment\n",
    "- ‚úÖ Modelos registrados en Model Registry\n",
    "- ‚úÖ Validaci√≥n en Staging antes de Production\n",
    "- ‚úÖ CI/CD pipeline automatizado\n",
    "- ‚úÖ Rollback plan documentado\n",
    "\n",
    "#### Monitoreo\n",
    "- ‚úÖ M√©tricas de performance rastreadas\n",
    "- ‚úÖ Data drift detectado autom√°ticamente\n",
    "- ‚úÖ Alertas configuradas\n",
    "- ‚úÖ Dashboard de monitoreo\n",
    "\n",
    "#### Gobernanza\n",
    "- ‚úÖ Documentaci√≥n de modelos\n",
    "- ‚úÖ Lineage de datos y modelos\n",
    "- ‚úÖ Pol√≠ticas de retenci√≥n\n",
    "- ‚úÖ Auditor√≠a de cambios\n",
    "\n",
    "### üîß Configuraci√≥n de Jobs en Databricks\n",
    "\n",
    "**Job de Reentrenamiento Mensual:**\n",
    "```python\n",
    "# Databricks Job Configuration\n",
    "{\n",
    "  \"name\": \"churn_model_retraining\",\n",
    "  \"schedule\": {\n",
    "    \"quartz_cron_expression\": \"0 0 1 * * ?\",  # 1er d√≠a de cada mes\n",
    "    \"timezone_id\": \"America/New_York\"\n",
    "  },\n",
    "  \"tasks\": [\n",
    "    {\n",
    "      \"task_key\": \"update_features\",\n",
    "      \"notebook_task\": {\n",
    "        \"notebook_path\": \"/Workflows/feature_engineering\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"task_key\": \"train_model\",\n",
    "      \"depends_on\": [{\"task_key\": \"update_features\"}],\n",
    "      \"notebook_task\": {\n",
    "        \"notebook_path\": \"/Workflows/model_training\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"task_key\": \"validate_model\",\n",
    "      \"depends_on\": [{\"task_key\": \"train_model\"}],\n",
    "      \"notebook_task\": {\n",
    "        \"notebook_path\": \"/Workflows/model_validation\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### üìö Recursos Adicionales\n",
    "\n",
    "- [Databricks MLOps Guide](https://docs.databricks.com/mlflow/index.html)\n",
    "- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)\n",
    "- [Feature Store Best Practices](https://docs.databricks.com/machine-learning/feature-store/index.html)\n",
    "- [Model Registry Guide](https://docs.databricks.com/machine-learning/model-registry/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Ejercicios Pr√°cticos\n",
    "\n",
    "### Ejercicio 1: Mejorar el Modelo\n",
    "1. Crea nuevas features derivadas (ej: ratio de datos vs minutos)\n",
    "2. Prueba XGBoost o LightGBM\n",
    "3. Implementa hyperparameter tuning con Hyperopt\n",
    "4. Compara resultados en MLflow\n",
    "\n",
    "### Ejercicio 2: Implementar A/B Testing\n",
    "1. Deploy dos versiones del modelo en Staging\n",
    "2. Divide tr√°fico 50/50\n",
    "3. Compara m√©tricas de negocio\n",
    "4. Promover el ganador a Production\n",
    "\n",
    "### Ejercicio 3: Dashboard de Monitoreo\n",
    "1. Crea una tabla de m√©tricas hist√≥ricas\n",
    "2. Visualiza trends de performance\n",
    "3. Detecta anomal√≠as en predicciones\n",
    "4. Configura alertas autom√°ticas\n",
    "\n",
    "### Ejercicio 4: CI/CD Pipeline\n",
    "1. Configura un Databricks Workflow\n",
    "2. Automatiza feature engineering\n",
    "3. Automatiza training y validation\n",
    "4. Implementa promoci√≥n autom√°tica a Staging\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Notas Finales\n",
    "\n",
    "Este notebook cubre el ciclo completo de MLOps:\n",
    "\n",
    "1. ‚úÖ **Feature Engineering** con Feature Store\n",
    "2. ‚úÖ **Experimentaci√≥n** con MLflow Tracking\n",
    "3. ‚úÖ **Versionado** con Model Registry\n",
    "4. ‚úÖ **Deployment** en Staging y Production\n",
    "5. ‚úÖ **Inferencia** batch y real-time\n",
    "6. ‚úÖ **Monitoreo** de performance y drift\n",
    "7. ‚úÖ **Automatizaci√≥n** con pipelines\n",
    "\n",
    "### üéØ Pr√≥ximos Pasos\n",
    "\n",
    "- Implementar serving con **Databricks Model Serving**\n",
    "- Integrar con sistemas externos (CRM, Marketing)\n",
    "- Configurar **Unity Catalog** para gobernanza\n",
    "- Implementar **drift detection** avanzado\n",
    "- Crear dashboards en **Databricks SQL**\n",
    "\n",
    "---\n",
    "\n",
    "**¬°Felicidades! Has completado el workshop de MLOps con Databricks** üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
