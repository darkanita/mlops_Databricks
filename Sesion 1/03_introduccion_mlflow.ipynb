{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IntroducciÃ³n a MLflow ðŸ¤–\n",
    "\n",
    "## ðŸ“š Objetivos de Aprendizaje\n",
    "\n",
    "En este notebook aprenderÃ¡s:\n",
    "1. Â¿QuÃ© es MLflow y por quÃ© lo necesitas?\n",
    "2. Los 4 componentes principales de MLflow\n",
    "3. MLflow Tracking: Rastrear experimentos\n",
    "4. MLflow Models: Empaquetar y versionar modelos\n",
    "5. MLflow Model Registry: GestiÃ³n del ciclo de vida\n",
    "6. Comandos y funciones esenciales\n",
    "7. Best practices\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Â¿QuÃ© es MLflow?\n",
    "\n",
    "**MLflow** es una plataforma open-source para gestionar el ciclo de vida completo de Machine Learning.\n",
    "\n",
    "### El Problema que Resuelve:\n",
    "\n",
    "Sin MLflow:\n",
    "```\n",
    "âŒ \"Â¿QuÃ© hiperparÃ¡metros usÃ© en ese experimento?\"\n",
    "âŒ \"Â¿CuÃ¡l era la versiÃ³n del modelo en producciÃ³n?\"\n",
    "âŒ \"No puedo reproducir los resultados de la semana pasada\"\n",
    "âŒ \"Â¿DÃ³nde guardÃ© ese modelo?\"\n",
    "âŒ \"Â¿QuÃ© datos usÃ© para entrenar?\"\n",
    "```\n",
    "\n",
    "Con MLflow:\n",
    "```\n",
    "âœ… Todos los experimentos rastreados automÃ¡ticamente\n",
    "âœ… Modelos versionados y organizados\n",
    "âœ… Reproducibilidad garantizada\n",
    "âœ… ComparaciÃ³n fÃ¡cil entre experimentos\n",
    "âœ… Deployment simplificado\n",
    "```\n",
    "\n",
    "### Â¿Para quiÃ©n es MLflow?\n",
    "\n",
    "- **Data Scientists**: ExperimentaciÃ³n y desarrollo de modelos\n",
    "- **ML Engineers**: Deployment y gestiÃ³n de modelos\n",
    "- **Equipos**: ColaboraciÃ³n y compartir modelos\n",
    "- **Organizaciones**: Gobernanza y compliance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ—ï¸ Los 4 Componentes de MLflow\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                       MLFLOW                            â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  1ï¸âƒ£ TRACKING                    2ï¸âƒ£ PROJECTS          â”‚\n",
    "â”‚  Rastrea experimentos           Empaqueta cÃ³digo       â”‚\n",
    "â”‚  - ParÃ¡metros                   - Reproducible         â”‚\n",
    "â”‚  - MÃ©tricas                     - Portable             â”‚\n",
    "â”‚  - Artefactos                   - Versionado           â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  3ï¸âƒ£ MODELS                      4ï¸âƒ£ MODEL REGISTRY    â”‚\n",
    "â”‚  Empaqueta modelos              Gestiona ciclo de vida â”‚\n",
    "â”‚  - Formato estÃ¡ndar             - Staging/Production   â”‚\n",
    "â”‚  - Multi-framework              - Versionado           â”‚\n",
    "â”‚  - Deployment fÃ¡cil             - ColaboraciÃ³n         â”‚\n",
    "â”‚                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### 1ï¸âƒ£ MLflow Tracking\n",
    "Registra y consulta experimentos:\n",
    "- ParÃ¡metros (learning rate, epochs, etc.)\n",
    "- MÃ©tricas (accuracy, loss, etc.)\n",
    "- Modelos y artefactos\n",
    "- CÃ³digo fuente y versiones\n",
    "\n",
    "### 2ï¸âƒ£ MLflow Projects\n",
    "Formato para empaquetar cÃ³digo de ML:\n",
    "- Dependencias explÃ­citas\n",
    "- Puntos de entrada definidos\n",
    "- ParÃ¡metros configurables\n",
    "\n",
    "### 3ï¸âƒ£ MLflow Models\n",
    "Formato estÃ¡ndar para modelos:\n",
    "- Funciona con sklearn, TensorFlow, PyTorch, etc.\n",
    "- Incluye metadata y dependencias\n",
    "- Deploy en mÃºltiples plataformas\n",
    "\n",
    "### 4ï¸âƒ£ MLflow Model Registry\n",
    "Repositorio centralizado de modelos:\n",
    "- Versionado automÃ¡tico\n",
    "- Transiciones de stage (Staging â†’ Production)\n",
    "- Anotaciones y descripciones\n",
    "- Control de acceso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš™ï¸ Setup y ConfiguraciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas\")\n",
    "print(f\"ðŸ“¦ MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar MLflow\n",
    "# En Databricks, MLflow ya estÃ¡ integrado\n",
    "\n",
    "# Obtener usuario actual\n",
    "username = spark.sql(\"SELECT current_user()\").first()[0]\n",
    "\n",
    "# Nombre del experimento (cada usuario tiene el suyo)\n",
    "experiment_name = f\"/Users/{username}/mlflow_intro_demo\"\n",
    "\n",
    "# Crear o usar experimento existente\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"ðŸ”¬ Experimento configurado: {experiment_name}\")\n",
    "print(f\"\\nðŸ“ Puedes ver tus experimentos en:\")\n",
    "print(f\"   Machine Learning > Experiments en el menÃº lateral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š Preparar Datos de Ejemplo\n",
    "\n",
    "Usaremos un dataset sintÃ©tico de clasificaciÃ³n binaria para demostrar MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar dataset sintÃ©tico\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=8,\n",
    "    n_redundant=2,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Crear DataFrame para mejor visualizaciÃ³n\n",
    "feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(f\"âœ… Dataset creado:\")\n",
    "print(f\"   Muestras: {len(df):,}\")\n",
    "print(f\"   Features: {X.shape[1]}\")\n",
    "print(f\"   Clases: {len(np.unique(y))}\")\n",
    "print(f\"\\nDistribuciÃ³n de clases:\")\n",
    "print(df['target'].value_counts())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"âœ… Datos divididos:\")\n",
    "print(f\"   Training: {len(X_train):,} samples\")\n",
    "print(f\"   Test: {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1ï¸âƒ£ MLflow Tracking: Conceptos BÃ¡sicos\n",
    "\n",
    "### JerarquÃ­a de MLflow:\n",
    "\n",
    "```\n",
    "Experiment (Experimento)\n",
    "  â””â”€â”€ Run (EjecuciÃ³n)\n",
    "       â”œâ”€â”€ Parameters (HiperparÃ¡metros)\n",
    "       â”œâ”€â”€ Metrics (MÃ©tricas)\n",
    "       â”œâ”€â”€ Tags (Etiquetas)\n",
    "       â”œâ”€â”€ Artifacts (Artefactos: modelos, plots, etc.)\n",
    "       â””â”€â”€ Model (Modelo empaquetado)\n",
    "```\n",
    "\n",
    "### Conceptos Clave:\n",
    "\n",
    "- **Experiment**: ColecciÃ³n de runs relacionados (ej: \"Clasificador de Clientes\")\n",
    "- **Run**: Un intento de entrenamiento (ej: \"Random Forest con max_depth=10\")\n",
    "- **Parameters**: ConfiguraciÃ³n del modelo (ej: learning_rate=0.01)\n",
    "- **Metrics**: Resultados del modelo (ej: accuracy=0.95)\n",
    "- **Artifacts**: Archivos generados (ej: modelo.pkl, plot.png)\n",
    "- **Tags**: Metadata adicional (ej: \"producciÃ³n\", \"experimental\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¥ Tu Primer Run en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJEMPLO BÃSICO: Entrenar modelo y rastrear con MLflow\n",
    "\n",
    "# Iniciar un run\n",
    "with mlflow.start_run(run_name=\"mi_primer_modelo\") as run:\n",
    "    \n",
    "    # 1. Log parÃ¡metros\n",
    "    mlflow.log_param(\"modelo\", \"Logistic Regression\")\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "    mlflow.log_param(\"solver\", \"lbfgs\")\n",
    "    \n",
    "    # 2. Entrenar modelo\n",
    "    model = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 3. Evaluar\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # 4. Log mÃ©tricas\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # 5. Log modelo\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"demo_classifier\"\n",
    "    )\n",
    "    \n",
    "    # 6. Log tags\n",
    "    mlflow.set_tag(\"tipo\", \"clasificacion\")\n",
    "    mlflow.set_tag(\"framework\", \"sklearn\")\n",
    "    \n",
    "    print(\"âœ… Run completado!\")\n",
    "    print(f\"\\nðŸ“Š MÃ©tricas:\")\n",
    "    print(f\"   Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"   Precision: {precision:.4f}\")\n",
    "    print(f\"   Recall:    {recall:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "    print(f\"\\nðŸ”— Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“ Comandos Esenciales de MLflow Tracking\n",
    "\n",
    "#### Iniciar/Terminar Runs:\n",
    "\n",
    "```python\n",
    "# OpciÃ³n 1: Context manager (recomendado)\n",
    "with mlflow.start_run(run_name=\"mi_experimento\") as run:\n",
    "    # Tu cÃ³digo aquÃ­\n",
    "    pass\n",
    "\n",
    "# OpciÃ³n 2: Manual\n",
    "run = mlflow.start_run()\n",
    "# Tu cÃ³digo\n",
    "mlflow.end_run()\n",
    "```\n",
    "\n",
    "#### Registrar ParÃ¡metros:\n",
    "\n",
    "```python\n",
    "# Un parÃ¡metro\n",
    "mlflow.log_param(\"learning_rate\", 0.01)\n",
    "\n",
    "# MÃºltiples parÃ¡metros\n",
    "mlflow.log_params({\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 32\n",
    "})\n",
    "```\n",
    "\n",
    "#### Registrar MÃ©tricas:\n",
    "\n",
    "```python\n",
    "# Una mÃ©trica\n",
    "mlflow.log_metric(\"accuracy\", 0.95)\n",
    "\n",
    "# MÃºltiples mÃ©tricas\n",
    "mlflow.log_metrics({\n",
    "    \"accuracy\": 0.95,\n",
    "    \"loss\": 0.23,\n",
    "    \"f1_score\": 0.92\n",
    "})\n",
    "\n",
    "# MÃ©trica con steps (para grÃ¡ficos de entrenamiento)\n",
    "for epoch in range(10):\n",
    "    mlflow.log_metric(\"loss\", loss_value, step=epoch)\n",
    "```\n",
    "\n",
    "#### Registrar Artefactos:\n",
    "\n",
    "```python\n",
    "# Archivo individual\n",
    "mlflow.log_artifact(\"plot.png\")\n",
    "\n",
    "# Directorio completo\n",
    "mlflow.log_artifacts(\"./outputs\")\n",
    "\n",
    "# Crear y guardar texto\n",
    "with open(\"readme.txt\", \"w\") as f:\n",
    "    f.write(\"DescripciÃ³n del modelo\")\n",
    "mlflow.log_artifact(\"readme.txt\")\n",
    "```\n",
    "\n",
    "#### Tags:\n",
    "\n",
    "```python\n",
    "# Un tag\n",
    "mlflow.set_tag(\"version\", \"v1.0\")\n",
    "\n",
    "# MÃºltiples tags\n",
    "mlflow.set_tags({\n",
    "    \"team\": \"data-science\",\n",
    "    \"priority\": \"high\"\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”„ Autolog: Tracking AutomÃ¡tico\n",
    "\n",
    "MLflow puede rastrear automÃ¡ticamente parÃ¡metros, mÃ©tricas y modelos segÃºn el framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOLOG DEMO\n",
    "\n",
    "# Activar autolog para sklearn\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "with mlflow.start_run(run_name=\"autolog_demo\") as run:\n",
    "    \n",
    "    # Solo entrenamos - MLflow registra todo automÃ¡ticamente\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciÃ³n para que autolog calcule mÃ©tricas\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"âœ… Modelo entrenado con autolog\")\n",
    "    print(\"\\nðŸ¤– MLflow registrÃ³ automÃ¡ticamente:\")\n",
    "    print(\"   - Todos los parÃ¡metros del modelo\")\n",
    "    print(\"   - Feature importances\")\n",
    "    print(\"   - Modelo serializado\")\n",
    "    print(\"   - Signature del modelo\")\n",
    "    print(f\"\\nðŸ”— Run ID: {run.info.run_id}\")\n",
    "\n",
    "# Desactivar autolog\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ” Comparar MÃºltiples Experimentos\n",
    "\n",
    "Una de las ventajas clave de MLflow es comparar diferentes configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar diferentes configuraciones de Random Forest\n",
    "\n",
    "configurations = [\n",
    "    {\"n_estimators\": 50, \"max_depth\": 5},\n",
    "    {\"n_estimators\": 100, \"max_depth\": 10},\n",
    "    {\"n_estimators\": 200, \"max_depth\": 15},\n",
    "    {\"n_estimators\": 100, \"max_depth\": None},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, config in enumerate(configurations):\n",
    "    with mlflow.start_run(run_name=f\"random_forest_config_{i+1}\") as run:\n",
    "        \n",
    "        # Log parÃ¡metros\n",
    "        mlflow.log_params(config)\n",
    "        \n",
    "        # Entrenar\n",
    "        model = RandomForestClassifier(**config, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluar\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Log mÃ©tricas\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        \n",
    "        # Guardar resultados para comparaciÃ³n\n",
    "        results.append({\n",
    "            \"config\": f\"Config {i+1}\",\n",
    "            \"n_estimators\": config[\"n_estimators\"],\n",
    "            \"max_depth\": config[\"max_depth\"],\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1_score\": f1,\n",
    "            \"run_id\": run.info.run_id\n",
    "        })\n",
    "        \n",
    "        print(f\"âœ… Config {i+1}: Accuracy={accuracy:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Comparar resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nðŸ“Š COMPARACIÃ“N DE CONFIGURACIONES:\\n\")\n",
    "display(results_df.sort_values(\"accuracy\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”Ž Buscar y Consultar Runs\n",
    "\n",
    "MLflow proporciona APIs para buscar y filtrar runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los runs del experimento actual\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "# Buscar runs\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"metrics.accuracy DESC\"],  # Ordenar por accuracy\n",
    "    max_results=10\n",
    ")\n",
    "\n",
    "print(\"ðŸ” Runs encontrados (ordenados por accuracy):\")\n",
    "display(runs[[\n",
    "    'run_id',\n",
    "    'tags.mlflow.runName',\n",
    "    'metrics.accuracy',\n",
    "    'metrics.f1_score',\n",
    "    'params.n_estimators',\n",
    "    'params.max_depth'\n",
    "]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar runs con condiciones\n",
    "high_accuracy_runs = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    filter_string=\"metrics.accuracy > 0.85\",  # Solo runs con accuracy > 85%\n",
    "    order_by=[\"metrics.f1_score DESC\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Runs con accuracy > 0.85: {len(high_accuracy_runs)}\")\n",
    "if len(high_accuracy_runs) > 0:\n",
    "    display(high_accuracy_runs[[\n",
    "        'tags.mlflow.runName',\n",
    "        'metrics.accuracy',\n",
    "        'metrics.f1_score'\n",
    "    ]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2ï¸âƒ£ MLflow Models: Empaquetar Modelos\n",
    "\n",
    "MLflow Models es un formato estÃ¡ndar para empaquetar modelos de ML de cualquier framework.\n",
    "\n",
    "### Ventajas:\n",
    "\n",
    "- âœ… **Framework agnÃ³stico**: sklearn, TensorFlow, PyTorch, etc.\n",
    "- âœ… **Incluye dependencias**: requirements.txt automÃ¡tico\n",
    "- âœ… **Signature**: Define input/output del modelo\n",
    "- âœ… **MÃºltiples formatos**: Python function, REST API, etc.\n",
    "- âœ… **Deployment fÃ¡cil**: Una lÃ­nea de cÃ³digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo con signature\n",
    "\n",
    "with mlflow.start_run(run_name=\"modelo_con_signature\") as run:\n",
    "    \n",
    "    # Entrenar\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Crear signature (define input/output)\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    \n",
    "    # Input example\n",
    "    input_example = X_train[:5]\n",
    "    \n",
    "    # Log modelo con metadata completa\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=\"demo_rf_classifier\"\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Modelo guardado con:\")\n",
    "    print(\"   - Signature (input/output schema)\")\n",
    "    print(\"   - Input example\")\n",
    "    print(\"   - Dependencias (conda.yaml, requirements.txt)\")\n",
    "    print(f\"\\nðŸ”— Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo guardado\n",
    "\n",
    "# OpciÃ³n 1: Desde un run especÃ­fico\n",
    "run_id = run.info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = loaded_model.predict(X_test[:5])\n",
    "\n",
    "print(\"âœ… Modelo cargado desde run\")\n",
    "print(f\"\\nPredicciones de ejemplo: {predictions}\")\n",
    "print(f\"Valores reales: {y_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ Formatos de Modelo MLflow\n",
    "\n",
    "MLflow puede guardar modelos en mÃºltiples formatos:\n",
    "\n",
    "```python\n",
    "# Scikit-learn\n",
    "mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "# PyTorch\n",
    "mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "# TensorFlow/Keras\n",
    "mlflow.tensorflow.log_model(model, \"model\")\n",
    "mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "# XGBoost\n",
    "mlflow.xgboost.log_model(model, \"model\")\n",
    "\n",
    "# LightGBM\n",
    "mlflow.lightgbm.log_model(model, \"model\")\n",
    "\n",
    "# Python function (custom)\n",
    "mlflow.pyfunc.log_model(python_model=custom_model, artifact_path=\"model\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3ï¸âƒ£ MLflow Model Registry: GestiÃ³n del Ciclo de Vida\n",
    "\n",
    "El Model Registry es un repositorio centralizado para gestionar modelos.\n",
    "\n",
    "### Stages del Ciclo de Vida:\n",
    "\n",
    "```\n",
    "None (Nuevo) â†’ Staging (Testing) â†’ Production (Activo) â†’ Archived (Deprecado)\n",
    "```\n",
    "\n",
    "### Flujo TÃ­pico:\n",
    "\n",
    "```\n",
    "1. Data Scientist entrena modelo\n",
    "   â†“\n",
    "2. Modelo se registra automÃ¡ticamente (None)\n",
    "   â†“\n",
    "3. Se promociona a Staging para testing\n",
    "   â†“\n",
    "4. DespuÃ©s de validaciÃ³n, va a Production\n",
    "   â†“\n",
    "5. Modelo antiguo se archiva\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trabajar con el Model Registry\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Nombre del modelo registrado\n",
    "model_name = \"demo_rf_classifier\"\n",
    "\n",
    "# Obtener todas las versiones del modelo\n",
    "versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "\n",
    "print(f\"ðŸ“¦ Modelo: {model_name}\")\n",
    "print(f\"ðŸ“Š Total de versiones: {len(versions)}\\n\")\n",
    "\n",
    "for version in versions[:3]:  # Mostrar primeras 3\n",
    "    print(f\"VersiÃ³n {version.version}:\")\n",
    "    print(f\"  Stage: {version.current_stage}\")\n",
    "    print(f\"  Run ID: {version.run_id}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transicionar modelo a diferentes stages\n",
    "\n",
    "# Obtener la Ãºltima versiÃ³n\n",
    "latest_version = versions[0].version if versions else 1\n",
    "\n",
    "print(f\"ðŸ”„ Transicionando versiÃ³n {latest_version} a Staging...\")\n",
    "\n",
    "# Mover a Staging\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=latest_version,\n",
    "    stage=\"Staging\",\n",
    "    archive_existing_versions=False  # No archivar otras versiones en Staging\n",
    ")\n",
    "\n",
    "print(\"âœ… Modelo en Staging\")\n",
    "\n",
    "# Agregar descripciÃ³n\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=latest_version,\n",
    "    description=\"Random Forest classifier entrenado con 100 Ã¡rboles y max_depth=10\"\n",
    ")\n",
    "\n",
    "print(\"âœ… DescripciÃ³n agregada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo desde Model Registry\n",
    "\n",
    "# OpciÃ³n 1: Por stage\n",
    "model_staging = mlflow.sklearn.load_model(f\"models:/{model_name}/Staging\")\n",
    "\n",
    "# OpciÃ³n 2: Por versiÃ³n especÃ­fica\n",
    "model_v1 = mlflow.sklearn.load_model(f\"models:/{model_name}/{latest_version}\")\n",
    "\n",
    "print(\"âœ… Modelos cargados desde Registry\")\n",
    "print(f\"   - Modelo en Staging\")\n",
    "print(f\"   - Modelo versiÃ³n {latest_version}\")\n",
    "\n",
    "# Hacer predicciÃ³n\n",
    "test_sample = X_test[:1]\n",
    "prediction = model_staging.predict(test_sample)\n",
    "print(f\"\\nðŸ”® PredicciÃ³n de ejemplo: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular promociÃ³n a Production\n",
    "\n",
    "print(\"ðŸš€ Simulando validaciÃ³n y promociÃ³n a Production...\\n\")\n",
    "\n",
    "# En la realidad, aquÃ­ harÃ­as:\n",
    "# - A/B testing\n",
    "# - ValidaciÃ³n con datos recientes\n",
    "# - RevisiÃ³n por equipo de ML\n",
    "\n",
    "# Promocionar a Production\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=latest_version,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True  # Archivar versiones anteriores en Production\n",
    ")\n",
    "\n",
    "print(f\"âœ… VersiÃ³n {latest_version} ahora en PRODUCTION\")\n",
    "print(\"ðŸ“¦ Versiones anteriores archivadas\")\n",
    "\n",
    "# Agregar tag\n",
    "client.set_model_version_tag(\n",
    "    name=model_name,\n",
    "    version=latest_version,\n",
    "    key=\"deployment_date\",\n",
    "    value=datetime.now().strftime(\"%Y-%m-%d\")\n",
    ")\n",
    "\n",
    "print(\"âœ… Tag de deployment agregado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”§ Comandos del Model Registry\n",
    "\n",
    "```python\n",
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "# Registrar modelo\n",
    "mlflow.register_model(\n",
    "    model_uri=\"runs:/run_id/model\",\n",
    "    name=\"my_model\"\n",
    ")\n",
    "\n",
    "# Buscar versiones\n",
    "versions = client.search_model_versions(\"name='my_model'\")\n",
    "\n",
    "# Obtener Ãºltima versiÃ³n\n",
    "latest_versions = client.get_latest_versions(\"my_model\", stages=[\"Production\"])\n",
    "\n",
    "# Transicionar stage\n",
    "client.transition_model_version_stage(\n",
    "    name=\"my_model\",\n",
    "    version=1,\n",
    "    stage=\"Production\"\n",
    ")\n",
    "\n",
    "# Actualizar descripciÃ³n\n",
    "client.update_model_version(\n",
    "    name=\"my_model\",\n",
    "    version=1,\n",
    "    description=\"DescripciÃ³n del modelo\"\n",
    ")\n",
    "\n",
    "# Agregar tags\n",
    "client.set_model_version_tag(\n",
    "    name=\"my_model\",\n",
    "    version=1,\n",
    "    key=\"team\",\n",
    "    value=\"data-science\"\n",
    ")\n",
    "\n",
    "# Eliminar versiÃ³n (solo si no estÃ¡ en Production)\n",
    "client.delete_model_version(\n",
    "    name=\"my_model\",\n",
    "    version=1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š VisualizaciÃ³n en la UI de MLflow\n",
    "\n",
    "### Acceder a la UI:\n",
    "\n",
    "En Databricks:\n",
    "1. MenÃº lateral â†’ **Machine Learning**\n",
    "2. Click en **Experiments**\n",
    "3. Encuentra tu experimento\n",
    "\n",
    "### QuÃ© puedes hacer en la UI:\n",
    "\n",
    "#### Experiments View:\n",
    "- âœ… Ver todos los runs de un experimento\n",
    "- âœ… Comparar runs lado a lado\n",
    "- âœ… Visualizar mÃ©tricas en grÃ¡ficos\n",
    "- âœ… Filtrar y buscar runs\n",
    "- âœ… Descargar artefactos\n",
    "\n",
    "#### Run Details:\n",
    "- âœ… ParÃ¡metros y mÃ©tricas\n",
    "- âœ… GrÃ¡ficos de mÃ©tricas vs steps\n",
    "- âœ… Artefactos (modelos, plots, etc.)\n",
    "- âœ… CÃ³digo fuente\n",
    "- âœ… InformaciÃ³n del sistema\n",
    "\n",
    "#### Model Registry:\n",
    "- âœ… Ver todas las versiones\n",
    "- âœ… Comparar versiones\n",
    "- âœ… Gestionar stages\n",
    "- âœ… Ver requests de transiciÃ³n\n",
    "- âœ… Webhooks y notificaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Best Practices\n",
    "\n",
    "### 1. OrganizaciÃ³n de Experimentos:\n",
    "\n",
    "```\n",
    "âœ… BIEN:\n",
    "/Users/tu_usuario/\n",
    "  â”œâ”€â”€ customer_churn_prediction/\n",
    "  â”œâ”€â”€ fraud_detection/\n",
    "  â””â”€â”€ recommendation_system/\n",
    "\n",
    "âŒ MAL:\n",
    "/Users/tu_usuario/\n",
    "  â”œâ”€â”€ experiment_1\n",
    "  â”œâ”€â”€ test\n",
    "  â””â”€â”€ new_model\n",
    "```\n",
    "\n",
    "### 2. Nombres de Runs:\n",
    "\n",
    "```python\n",
    "# âœ… Descriptivos\n",
    "run_name = \"rf_100trees_depth10_2024-01-15\"\n",
    "run_name = \"logistic_baseline_v1\"\n",
    "\n",
    "# âŒ Poco informativos\n",
    "run_name = \"test\"\n",
    "run_name = \"run1\"\n",
    "```\n",
    "\n",
    "### 3. QuÃ© Registrar:\n",
    "\n",
    "**SIEMPRE registra:**\n",
    "- âœ… Todos los hiperparÃ¡metros\n",
    "- âœ… MÃ©tricas de evaluaciÃ³n\n",
    "- âœ… InformaciÃ³n del dataset (tamaÃ±o, features, etc.)\n",
    "- âœ… VersiÃ³n del cÃ³digo/modelo\n",
    "\n",
    "**Considera registrar:**\n",
    "- ðŸ“Š Plots de performance\n",
    "- ðŸ“Š Confusion matrices\n",
    "- ðŸ“Š Feature importances\n",
    "- ðŸ“Š InformaciÃ³n del cluster/ambiente\n",
    "\n",
    "### 4. Tags Ãštiles:\n",
    "\n",
    "```python\n",
    "mlflow.set_tags({\n",
    "    \"team\": \"data-science\",\n",
    "    \"project\": \"customer-retention\",\n",
    "    \"model_type\": \"classification\",\n",
    "    \"status\": \"experimental\",\n",
    "    \"git_commit\": \"abc123\",\n",
    "    \"author\": \"tu_nombre\"\n",
    "})\n",
    "```\n",
    "\n",
    "### 5. Model Registry:\n",
    "\n",
    "```\n",
    "âœ… Una sola fuente de verdad\n",
    "âœ… Siempre usar stages (None â†’ Staging â†’ Production)\n",
    "âœ… Describir cambios en cada versiÃ³n\n",
    "âœ… Archivar modelos obsoletos\n",
    "âœ… Tags para metadata adicional\n",
    "```\n",
    "\n",
    "### 6. Limpieza:\n",
    "\n",
    "```python\n",
    "# Eliminar runs experimentales fallidos\n",
    "client.delete_run(run_id)\n",
    "\n",
    "# Archivar experimentos viejos\n",
    "# (No hay delete de experimentos en Databricks MLflow)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ“ Ejercicios PrÃ¡cticos\n",
    "\n",
    "### Ejercicio 1: ExperimentaciÃ³n BÃ¡sica\n",
    "1. Entrena 3 modelos diferentes (ej: Logistic Regression, Random Forest, Gradient Boosting)\n",
    "2. Registra parÃ¡metros, mÃ©tricas y modelos con MLflow\n",
    "3. Compara los resultados en la UI\n",
    "4. Identifica el mejor modelo\n",
    "\n",
    "### Ejercicio 2: Hyperparameter Tuning\n",
    "1. Usa un loop para probar diferentes configuraciones de hiperparÃ¡metros\n",
    "2. Registra cada configuraciÃ³n como un run separado\n",
    "3. Usa `mlflow.search_runs()` para encontrar la mejor configuraciÃ³n\n",
    "4. Visualiza las mÃ©tricas vs parÃ¡metros\n",
    "\n",
    "### Ejercicio 3: Model Registry Workflow\n",
    "1. Registra tu mejor modelo en el Model Registry\n",
    "2. TransiÃ³nalo a Staging\n",
    "3. Carga el modelo desde Staging y haz predicciones\n",
    "4. AgrÃ©gale descripciÃ³n y tags\n",
    "5. PromociÃ³nalo a Production\n",
    "\n",
    "### Ejercicio 4: Autolog\n",
    "1. Activa autolog para sklearn\n",
    "2. Entrena un modelo complejo (ej: GridSearchCV)\n",
    "3. Revisa quÃ© registrÃ³ automÃ¡ticamente MLflow\n",
    "4. Compara con un run manual\n",
    "\n",
    "### Ejercicio 5: Custom Artifacts\n",
    "1. Crea un plot de confusion matrix\n",
    "2. GuÃ¡rdalo como imagen\n",
    "3. RegÃ­stralo como artefacto con `mlflow.log_artifact()`\n",
    "4. Crea un archivo de texto con el classification report\n",
    "5. RegÃ­stralo tambiÃ©n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESPACIO PARA TUS EJERCICIOS\n",
    "\n",
    "# Ejercicio 1: Tu cÃ³digo aquÃ­\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“š Comandos de Referencia RÃ¡pida\n",
    "\n",
    "### Setup y ConfiguraciÃ³n:\n",
    "```python\n",
    "import mlflow\n",
    "mlflow.set_experiment(\"/Users/usuario/mi_experimento\")\n",
    "```\n",
    "\n",
    "### Tracking:\n",
    "```python\n",
    "with mlflow.start_run(run_name=\"mi_run\") as run:\n",
    "    mlflow.log_param(\"param\", value)\n",
    "    mlflow.log_params({\"p1\": v1, \"p2\": v2})\n",
    "    mlflow.log_metric(\"metric\", value)\n",
    "    mlflow.log_metrics({\"m1\": v1, \"m2\": v2})\n",
    "    mlflow.log_artifact(\"file.txt\")\n",
    "    mlflow.set_tag(\"tag\", \"value\")\n",
    "```\n",
    "\n",
    "### Models:\n",
    "```python\n",
    "# Guardar\n",
    "mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "# Cargar desde run\n",
    "model = mlflow.sklearn.load_model(f\"runs:/{run_id}/model\")\n",
    "\n",
    "# Cargar desde registry\n",
    "model = mlflow.sklearn.load_model(\"models:/modelo/Production\")\n",
    "```\n",
    "\n",
    "### Model Registry:\n",
    "```python\n",
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "# Registrar\n",
    "mlflow.register_model(\"runs:/run_id/model\", \"nombre_modelo\")\n",
    "\n",
    "# Transicionar\n",
    "client.transition_model_version_stage(\n",
    "    name=\"modelo\", version=1, stage=\"Production\"\n",
    ")\n",
    "```\n",
    "\n",
    "### BÃºsqueda:\n",
    "```python\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_ids=[\"id\"],\n",
    "    filter_string=\"metrics.accuracy > 0.9\",\n",
    "    order_by=[\"metrics.accuracy DESC\"]\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Resumen de Conceptos Clave\n",
    "\n",
    "âœ… **MLflow Tracking** = Registrar experimentos (params, metrics, artifacts)  \n",
    "âœ… **MLflow Models** = Empaquetar modelos en formato estÃ¡ndar  \n",
    "âœ… **Model Registry** = Gestionar ciclo de vida (Staging â†’ Production)  \n",
    "âœ… **Autolog** = Tracking automÃ¡tico segÃºn framework  \n",
    "âœ… **Signature** = Define input/output del modelo  \n",
    "âœ… **Stages** = None â†’ Staging â†’ Production â†’ Archived  \n",
    "\n",
    "### Flujo Completo:\n",
    "\n",
    "```\n",
    "1. Experimentar â†’ mlflow.start_run()\n",
    "2. Registrar â†’ log_param(), log_metric()\n",
    "3. Guardar modelo â†’ log_model()\n",
    "4. Registrar en Registry â†’ register_model()\n",
    "5. Validar â†’ Staging\n",
    "6. ProducciÃ³n â†’ Production\n",
    "7. Monitorear â†’ Buscar y comparar runs\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Â¡Felicidades! Has completado la introducciÃ³n a MLflow** ðŸŽ‰\n",
    "\n",
    "Ahora estÃ¡s listo para el siguiente notebook: **03_MLOps_Completo_Databricks.ipynb**  \n",
    "donde integraremos todo lo aprendido en un workflow completo de MLOps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
